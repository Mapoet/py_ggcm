-------------------------------------- TODO -------------------------------------------
This file contains thoughs and ideas for improvements that could be made to py_ggcm.

General Philosohpy:
    If a function requires more than 20 lines of real code (comments and spaces don't 
    count), the function should probably be broken into smaller subfunctions, and the
    larger the function, the more likely it is it should be broken up.

CAUTION:
    For portability, the basemap toolkit and certain other imports are
    stored in my local home directory and are required to run the simulation. Also,
    Matplotlib 3 is needed to make the streamline plots.

General Note:
    In case you're wondering, I've tried to keep my lines maxed at 88. Why I chose this
    number? I don't know. Feel free to change it, but do try to stick to a consistent
    line length. This comment might be more relevant in the README file...

Website:
    Loading Less --
        Currently the website tries to load all the files for all the views when it
        starts up. This is from when there were only a few options, and not many files.
        Unfortunately there are now A LOT of files, and it is bogging everything down.
        The site should really only load the files immediately necessary.

ggcm_simulation:
    Merging swdata object --
        The swdata methods in the swdata class should really be included in the
        openggcm class considering it's not used anywhere else and having the
        object defined in openggcm only takes up extra space.
    
    Other types of run? --
        As some point, I had the idea that Run could be inherited from to define other
        types of run.

ggcm_datasets:
    Specifying datasets --
        Ideally the specific datasets would be automatically generated by some fairly
        simple code, using a file with the necessary information compactly stated. One
        of the major hurdles (and the reason I haven't done it yet) is automating the
        generation of the calculated datasets. I am not sure if there even is a general
        way to generate those, so some or all of them may have to be an exception.

    Efficiency --
        The dataset objects currently store the last information they loaded from the
        simulation outputs for use by other datasets using the same time. However,
        the datasets are called in separate processes so there is currently no actual
        advantage. It is worth examining whether it is worth trying to bridge that
        process gap somehow. I would not recommend trying to communicate between
        processes (too complicated), but it may be feesible to devise a way to read the
        files before splitting into the new process.

ggcm_dir, My_Re, and ggcm_exceptions:
    Phase out --
        These files define special methods and objects that are not strictly needed,
        although they made life (to my mind) simpler. However, they would make it hard
        to move the code elsewhere, so they should be phased out and replaced with
        builtin methods and objects.
